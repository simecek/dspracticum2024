{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf61b52-0b9d-4949-bccc-c1b6731d0d76",
   "metadata": {},
   "source": [
    "# Talk to LLMs & evaluate them on a simple benchmark\n",
    "\n",
    "Adapted from https://github.com/simecek/MiniCzechBenchmark/blob/main/minicz_bench.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bde11-8c7c-4fec-93c7-117f8743976a",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "MODEL = 'unsloth/gemma-2-2b' # hf hub model, e.g. mistralai/Mistral-7B-Instruct-v0.3\n",
    "\n",
    "HF_TOKEN = ''  # HF token needed to access gated models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc236d33-d4e7-4268-9e4e-bc192331cdb1",
   "metadata": {},
   "source": [
    "## Text-generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe84ff-420c-458f-93d1-384171f67c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import login\n",
    "#login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99040a4-8b0d-4e9e-941b-a141fd269805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL)  # needed by granite models\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=MODEL,\n",
    "    tokenizer=tok,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}, \n",
    "    device_map=\"auto\",\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    pad_token_id=tok.eos_token_id,\n",
    ")\n",
    "\n",
    "# Explicitly set pad_token_id to eos_token_id to prevent the warning\n",
    "pipe.model.config.pad_token_id = pipe.model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf219d4-8961-48a2-b0eb-683c4a3de617",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\"Å˜ekni mi vtip\", return_full_text=True, max_new_tokens=50)\n",
    "\n",
    "output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1361171-13cc-4c0d-93d8-a0bb0d39b1cc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEW_TOKENS = {\n",
    "    'agree': 2,\n",
    "    'czech_news': 2,\n",
    "    'klokanek': 2,\n",
    "    'ctkfacts': 2\n",
    "}\n",
    "\n",
    "def message_function(user_prompts, system_prompts):\n",
    "    messages = [f\"{system_prompt}\\n\\n{user_prompt}\" for system_prompt, user_prompt in zip(system_prompts, user_prompts)]\n",
    "    return messages\n",
    "\n",
    "def cleaning_function(raw_outputs):\n",
    "    return [x[0]['generated_text'][:3].strip().replace(\")\", \"\").replace(\".\", \"\") for x in raw_outputs]\n",
    "\n",
    "DATASETS = {\n",
    "        'agree': 'simecek/mini_agree',\n",
    "        'czech_news': 'simecek/mini_czech_news',\n",
    "        'klokanek': 'simecek/mini_klokanek',\n",
    "        'ctkfacts': 'simecek/mini_ctkfacts'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c9eaf-bb52-4a48-a2dc-3bdf3c27f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs = {}  # raw outputs from llm\n",
    "clean_outputs = {}  # after cleaning\n",
    "dfs = {}  # dataframe comparing clean_outputs to correct answers\n",
    "metrics = {}  # overall summaries for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e1147-876e-4722-9f11-153f33033f0d",
   "metadata": {},
   "source": [
    "### Czech News benchmark - 200 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65054088-c1f7-41f6-a109-e426db8028ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'czech_news'\n",
    "\n",
    "dt = load_dataset(DATASETS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69908753-7784-4bcc-9adf-2a5f1d3de26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt['train']['system_prompt'][0][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfe05f-d267-4425-b58d-8844e23ad961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt['train']['user_prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f6409-c3ac-4c32-af95-fd0aef5c0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt['train']['category'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9b67d-81d6-4f1d-ba49-16d2009cac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = message_function(dt['train']['user_prompt'], dt['train']['system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d856af0-3968-42ec-9373-96779559a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipe(messages[:5], return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbb407-6827-4a4b-86bd-9219a684a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs[dataset_name] = pipe(messages, return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5be339-050d-4cc8-98fa-bcd8bf5d363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outputs[dataset_name] = cleaning_function(raw_outputs[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b0cb8-58e3-4201-8000-aa382068bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs[dataset_name] = pd.DataFrame({\n",
    "    'correct_answer': dt['train']['category'],\n",
    "    'answer': clean_outputs[dataset_name],\n",
    "})\n",
    "\n",
    "dfs[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f7237-7e2f-4452-9435-7b5c3e74c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name]['valid'] = dfs[dataset_name].answer.isin(['1', '2', '3', '4', '5'])\n",
    "dfs[dataset_name]['correct'] = dfs[dataset_name].answer.apply(str) == dfs[dataset_name].correct_answer.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298c1b8-1442-403d-bf33-aab782b0dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct answers vs valid answers\n",
    "metrics[dataset_name] = (dfs[dataset_name]['valid'].mean().item(), dfs[dataset_name].correct.mean().item())\n",
    "metrics[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6a8c3-8f17-4861-85f2-498b6125ef22",
   "metadata": {},
   "source": [
    "Now try to improve the results:\n",
    "* use `unsloth/gemma-2-2b`\n",
    "* remove sampling and set `temperature` as `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314d003-e2e0-4569-af38-77b433334eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
